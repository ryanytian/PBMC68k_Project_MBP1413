{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from scipy.io import mmread\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9-D latent space\n",
    "latent_dims = 9\n",
    "num_epochs = 100\n",
    "learning_rate = 1e-3\n",
    "variational_beta = 1\n",
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. VAE definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, layer_size_list, output_size):\n",
    "        \n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # Define hidden layers\n",
    "        self.hidden = nn.ModuleList()\n",
    "        for k in range(len(layer_size_list)-1):\n",
    "            self.hidden.append(nn.Linear(layer_size_list[k], layer_size_list[k+1]))\n",
    "       \n",
    "        # fc_mu layer and fc_logvar\n",
    "        self.fc_mu = nn.Linear(in_features=layer_size_list[-1], out_features=output_size)\n",
    "        self.fc_logvar = nn.Linear(in_features=layer_size_list[-1], out_features=output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Feedforward        \n",
    "        for k in range(len(self.hidden)-1):\n",
    "            x = F.relu(self.hidden[k](x))\n",
    "\n",
    "        # Generate output before mu and logvar\n",
    "        x = self.hidden[-1](x)\n",
    "\n",
    "        # Generate fc_mu and fc_logvar\n",
    "        x_mu = self.fc_mu(x)\n",
    "        x_logvar = self.fc_logvar(x)\n",
    "\n",
    "        return x_mu, x_logvar\n",
    "\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, layer_size_list_reversed):\n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        # Output layer to first hidden layer\n",
    "        self.input = nn.Linear(output_size, layer_size_list_reversed[0])\n",
    "\n",
    "        # Define hidden layers\n",
    "        self.hidden = nn.ModuleList()\n",
    "        for k in range(len(layer_size_list_reversed)-1):\n",
    "            self.hidden.append(nn.Linear(layer_size_list_reversed[k], layer_size_list_reversed[k+1]))\n",
    "                   \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Feedforward\n",
    "        \n",
    "        x = self.input(x)\n",
    "        \n",
    "        for k in range(len(self.hidden)-1):\n",
    "            x = F.relu(self.hidden[k](x))\n",
    "\n",
    "        x = self.hidden[-1](x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    \n",
    "class VariationalAutoencoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, layer_size_list, output_size, input_size, layer_size_list_reversed):\n",
    "        \n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder(layer_size_list, output_size)\n",
    "        self.decoder = Decoder(input_size, layer_size_list_reversed)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        latent_mu, latent_logvar = self.encoder(x)\n",
    "        latent = self.latent_sample(latent_mu, latent_logvar)\n",
    "        x_recon = self.decoder(latent)\n",
    "        \n",
    "        return x_recon, latent_mu, latent_logvar\n",
    "    \n",
    "    def latent_sample(self, mu, logvar):\n",
    "        \n",
    "        if self.training:\n",
    "            \n",
    "            # the reparameterization trick\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = torch.empty_like(std).normal_()\n",
    "            return eps.mul(std).add_(mu)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            return mu\n",
    "\n",
    "\n",
    "def vae_loss(recon_x, x, mu, logvar):\n",
    "    \n",
    "    recon_loss = F.mse_loss(recon_x, x, reduction='sum')\n",
    "    \n",
    "    # KL-divergence between the prior distribution over latent vectors\n",
    "    # (the one we are going to sample from when generating new images)\n",
    "    # and the distribution estimated by the generator for the given image.\n",
    "    kldivergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    return recon_loss + variational_beta * kldivergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 3309881\n"
     ]
    }
   ],
   "source": [
    "# Encoder parameters\n",
    "layer_size_list = [32738, 50, 25]\n",
    "output_size = latent_dims\n",
    "\n",
    "# Decoder parameters\n",
    "input_size = latent_dims\n",
    "layer_size_list_reversed = [25, 50, 32738]\n",
    "\n",
    "vae = VariationalAutoencoder(layer_size_list, output_size, input_size, layer_size_list_reversed)\n",
    "\n",
    "num_params = sum(p.numel() for p in vae.parameters() if p.requires_grad)\n",
    "print('Number of parameters: %d' % num_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load data and train VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original working directory: /Users/ryanyutian/Desktop/PBMC68k_project/python_scripts\n",
      "Current working directory: /Users/ryanyutian/Desktop/PBMC68k_project/input_data_pure/all\n"
     ]
    }
   ],
   "source": [
    "# Change directory\n",
    "\n",
    "print(\"Original working directory: {0}\".format(os.getcwd()))\n",
    "\n",
    "path = '/Users/ryanyutian/Desktop/PBMC68k_project/input_data_pure/all'\n",
    "\n",
    "try:\n",
    "    os.chdir(path)\n",
    "    print(\"Current working directory: {0}\".format(os.getcwd()))\n",
    "except FileNotFoundError:\n",
    "    print(\"Directory: {0} does not exist\".format(path))\n",
    "except NotADirectoryError:\n",
    "    print(\"{0} is not a directory\".format(path))\n",
    "except PermissionError:\n",
    "    print(\"You do not have permissions to change to {0}\".format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing: normalized_expression_1.mtx\n",
      "Current Time = 18:24:20\n",
      "Analyzing: normalized_expression_10.mtx\n",
      "Current Time = 18:24:37\n",
      "Analyzing: normalized_expression_2.mtx\n",
      "Current Time = 18:24:39\n",
      "Analyzing: normalized_expression_3.mtx\n",
      "Current Time = 18:24:48\n",
      "Analyzing: normalized_expression_4.mtx\n",
      "Current Time = 18:24:57\n",
      "Analyzing: normalized_expression_5.mtx\n",
      "Current Time = 18:25:07\n",
      "Analyzing: normalized_expression_6.mtx\n",
      "Current Time = 18:25:18\n",
      "Analyzing: normalized_expression_7.mtx\n",
      "Current Time = 18:25:28\n",
      "Analyzing: normalized_expression_8.mtx\n",
      "Current Time = 18:25:38\n",
      "Analyzing: normalized_expression_9.mtx\n",
      "Current Time = 18:25:46\n"
     ]
    }
   ],
   "source": [
    "# Obtain all normalized expression arrays and save their variable names for later use \n",
    "\n",
    "normalized_expression_pure_array_names = []\n",
    "\n",
    "for file_name in sorted([i for i in os.listdir(path) if i.startswith('normalized_expression')]):\n",
    "    \n",
    "    print('Analyzing: ' + file_name)\n",
    "    print('Current Time =', datetime.now().strftime(\"%H:%M:%S\"))\n",
    "    \n",
    "    # Import sparse matrix of normalized expression then turn into np.array\n",
    "    # (e.g., 'normalized_expression_1' would be mtx for all normalized expressions for cell type 1)\n",
    "    temp_mtx = mmread(file_name)\n",
    "    \n",
    "    array_name = file_name[:-4]\n",
    "    globals()[array_name] = temp_mtx.toarray(order='C')\n",
    "\n",
    "    # Add name of the global array variable to the list of names\n",
    "    normalized_expression_pure_array_names.append(array_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_expression_pure_array_names.remove('normalized_expression_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all the normalized expression arrays to generate input data and labels\n",
    "\n",
    "normalized_expression_pure_array = []\n",
    "cell_labels_pure = []\n",
    "\n",
    "for array_name in normalized_expression_pure_array_names:\n",
    "\n",
    "    for cell in globals()[array_name]:\n",
    "        \n",
    "        # Append the expression profile of each cell\n",
    "        normalized_expression_pure_array.append(cell)\n",
    "        \n",
    "        # Append label of the cell based on array name (e.g., 10, 11, ...etc.)\n",
    "        # Note that -1 is applied to all labels due to R to Python transition\n",
    "        cell_labels_pure.append(int(array_name.split('_')[2]) - 1)\n",
    "    \n",
    "normalized_expression_pure_array = np.array(normalized_expression_pure_array)\n",
    "cell_labels_pure = np.array(cell_labels_pure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and testing set from the pure data\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(normalized_expression_pure_array, cell_labels_pure, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8]),\n",
       " array([7411, 6753, 8365, 8182, 9538, 8170, 8103, 8107, 9005]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8]),\n",
       " array([1821, 1632, 2114, 2081, 2415, 2054, 2106, 1978, 2208]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for i in range(len(X_train)):\n",
    "    train_data.append([X_train[i], y_train[i]])\n",
    "\n",
    "trainloader = DataLoader(train_data, shuffle=True, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for i in range(len(X_test)):\n",
    "    test_data.append([X_test[i], y_test[i]])\n",
    "\n",
    "testloader = DataLoader(test_data, shuffle=True, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "Epoch [1 / 100] average reconstruction error: 1738.922490\n",
      "Epoch [1 / 100] average testing reconstruction error: 25.072674\n",
      "Current time:  09:38:15\n",
      "Epoch [2 / 100] average reconstruction error: 10.346063\n",
      "Epoch [3 / 100] average reconstruction error: 0.647902\n",
      "Epoch [4 / 100] average reconstruction error: 0.187387\n",
      "Epoch [5 / 100] average reconstruction error: 0.167144\n",
      "Epoch [6 / 100] average reconstruction error: 0.137439\n",
      "Epoch [7 / 100] average reconstruction error: 0.136988\n",
      "Epoch [8 / 100] average reconstruction error: 0.132989\n",
      "Epoch [9 / 100] average reconstruction error: 0.154454\n",
      "Epoch [10 / 100] average reconstruction error: 0.160365\n",
      "Epoch [11 / 100] average reconstruction error: 0.212523\n",
      "Epoch [12 / 100] average reconstruction error: 0.225304\n",
      "Epoch [13 / 100] average reconstruction error: 0.274510\n",
      "Epoch [14 / 100] average reconstruction error: 0.223986\n",
      "Epoch [15 / 100] average reconstruction error: 0.223694\n",
      "Epoch [16 / 100] average reconstruction error: 0.249454\n",
      "Epoch [17 / 100] average reconstruction error: 0.283739\n",
      "Epoch [18 / 100] average reconstruction error: 0.197915\n",
      "Epoch [19 / 100] average reconstruction error: 0.197530\n",
      "Epoch [20 / 100] average reconstruction error: 0.214241\n",
      "Epoch [21 / 100] average reconstruction error: 0.219534\n",
      "Epoch [22 / 100] average reconstruction error: 0.212666\n",
      "Epoch [23 / 100] average reconstruction error: 0.219663\n",
      "Epoch [24 / 100] average reconstruction error: 0.257927\n",
      "Epoch [25 / 100] average reconstruction error: 0.153752\n",
      "Epoch [26 / 100] average reconstruction error: 0.249730\n",
      "Epoch [27 / 100] average reconstruction error: 0.180104\n",
      "Epoch [28 / 100] average reconstruction error: 0.191389\n",
      "Epoch [29 / 100] average reconstruction error: 0.200715\n",
      "Epoch [30 / 100] average reconstruction error: 0.186517\n",
      "Epoch [31 / 100] average reconstruction error: 0.198934\n",
      "Epoch [32 / 100] average reconstruction error: 0.202635\n",
      "Epoch [33 / 100] average reconstruction error: 0.206074\n",
      "Epoch [34 / 100] average reconstruction error: 0.202159\n",
      "Epoch [35 / 100] average reconstruction error: 0.164788\n",
      "Epoch [36 / 100] average reconstruction error: 0.198003\n",
      "Epoch [37 / 100] average reconstruction error: 0.164759\n",
      "Epoch [38 / 100] average reconstruction error: 0.182853\n",
      "Epoch [39 / 100] average reconstruction error: 0.192574\n",
      "Epoch [40 / 100] average reconstruction error: 0.163912\n",
      "Epoch [41 / 100] average reconstruction error: 0.183111\n",
      "Epoch [42 / 100] average reconstruction error: 0.172399\n",
      "Epoch [43 / 100] average reconstruction error: 0.156896\n",
      "Epoch [44 / 100] average reconstruction error: 0.169286\n",
      "Epoch [45 / 100] average reconstruction error: 0.170041\n",
      "Epoch [46 / 100] average reconstruction error: 0.155835\n",
      "Epoch [47 / 100] average reconstruction error: 0.165003\n",
      "Epoch [48 / 100] average reconstruction error: 0.162772\n",
      "Epoch [49 / 100] average reconstruction error: 0.153937\n",
      "Epoch [50 / 100] average reconstruction error: 0.155807\n",
      "Epoch [50 / 100] average testing reconstruction error: 0.147242\n",
      "Current time:  13:43:22\n",
      "Epoch [51 / 100] average reconstruction error: 0.156154\n",
      "Epoch [52 / 100] average reconstruction error: 0.155965\n",
      "Epoch [53 / 100] average reconstruction error: 0.153738\n",
      "Epoch [54 / 100] average reconstruction error: 0.148997\n",
      "Epoch [55 / 100] average reconstruction error: 0.152652\n",
      "Epoch [56 / 100] average reconstruction error: 0.148063\n",
      "Epoch [57 / 100] average reconstruction error: 0.153114\n",
      "Epoch [58 / 100] average reconstruction error: 0.144801\n",
      "Epoch [59 / 100] average reconstruction error: 0.148658\n",
      "Epoch [60 / 100] average reconstruction error: 0.151643\n",
      "Epoch [61 / 100] average reconstruction error: 0.139316\n",
      "Epoch [62 / 100] average reconstruction error: 0.148667\n",
      "Epoch [63 / 100] average reconstruction error: 0.142641\n",
      "Epoch [64 / 100] average reconstruction error: 0.145958\n",
      "Epoch [65 / 100] average reconstruction error: 0.139099\n",
      "Epoch [66 / 100] average reconstruction error: 0.142642\n",
      "Epoch [67 / 100] average reconstruction error: 0.142929\n",
      "Epoch [68 / 100] average reconstruction error: 0.140077\n",
      "Epoch [69 / 100] average reconstruction error: 0.141505\n",
      "Epoch [70 / 100] average reconstruction error: 0.138216\n",
      "Epoch [71 / 100] average reconstruction error: 0.140026\n",
      "Epoch [72 / 100] average reconstruction error: 0.139077\n",
      "Epoch [73 / 100] average reconstruction error: 0.137136\n",
      "Epoch [74 / 100] average reconstruction error: 0.138044\n",
      "Epoch [75 / 100] average reconstruction error: 0.136977\n",
      "Epoch [76 / 100] average reconstruction error: 0.136637\n",
      "Epoch [77 / 100] average reconstruction error: 0.135997\n",
      "Epoch [78 / 100] average reconstruction error: 0.135779\n",
      "Epoch [79 / 100] average reconstruction error: 0.135360\n",
      "Epoch [80 / 100] average reconstruction error: 0.135657\n",
      "Epoch [81 / 100] average reconstruction error: 0.134753\n",
      "Epoch [82 / 100] average reconstruction error: 0.134969\n",
      "Epoch [83 / 100] average reconstruction error: 0.134370\n",
      "Epoch [84 / 100] average reconstruction error: 0.134315\n",
      "Epoch [85 / 100] average reconstruction error: 0.134223\n",
      "Epoch [86 / 100] average reconstruction error: 0.134009\n",
      "Epoch [87 / 100] average reconstruction error: 0.133954\n",
      "Epoch [88 / 100] average reconstruction error: 0.133795\n",
      "Epoch [89 / 100] average reconstruction error: 0.133865\n",
      "Epoch [90 / 100] average reconstruction error: 0.133839\n",
      "Epoch [91 / 100] average reconstruction error: 0.133833\n",
      "Epoch [92 / 100] average reconstruction error: 0.133815\n",
      "Epoch [93 / 100] average reconstruction error: 0.133786\n",
      "Epoch [94 / 100] average reconstruction error: 0.133838\n",
      "Epoch [95 / 100] average reconstruction error: 0.133873\n",
      "Epoch [96 / 100] average reconstruction error: 0.133775\n",
      "Epoch [97 / 100] average reconstruction error: 0.133848\n",
      "Epoch [98 / 100] average reconstruction error: 0.133794\n",
      "Epoch [99 / 100] average reconstruction error: 0.133831\n",
      "Epoch [100 / 100] average reconstruction error: 0.133844\n",
      "Epoch [100 / 100] average testing reconstruction error: 0.139142\n",
      "Current time:  23:58:04\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(params=vae.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "train_loss_avg = []\n",
    "test_loss_avg = []\n",
    "\n",
    "print('Training ...')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # set to training mode\n",
    "    vae.train()\n",
    "\n",
    "    train_loss_avg.append(0)\n",
    "    num_batches = 0\n",
    "    \n",
    "    for cell_batch, _ in trainloader:\n",
    "        \n",
    "        # vae reconstruction\n",
    "        x_recon, latent_mu, latent_logvar = vae(cell_batch.to(torch.float32))\n",
    "        \n",
    "        # reconstruction error\n",
    "        loss = vae_loss(x_recon, cell_batch.to(torch.float32), latent_mu, latent_logvar)\n",
    "        \n",
    "        # backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # one step of the optmizer (using the gradients from backpropagation)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss_avg[-1] += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "    train_loss_avg[-1] /= num_batches\n",
    "    print('Epoch [%d / %d] average reconstruction error: %f' % (epoch+1, num_epochs, train_loss_avg[-1]))\n",
    "    \n",
    "    # Update test performance every 50 epochs\n",
    "    if epoch == 0 or (epoch + 1) % 50 == 0:\n",
    "        \n",
    "        # set to testing mode\n",
    "        vae.eval()\n",
    "        \n",
    "        test_loss_avg.append(0)\n",
    "        num_batches = 0\n",
    "\n",
    "        for cell_batch, _ in testloader:\n",
    "\n",
    "            # vae reconstruction\n",
    "            x_recon, latent_mu, latent_logvar = vae(cell_batch.to(torch.float32))\n",
    "\n",
    "            # reconstruction error\n",
    "            loss = vae_loss(x_recon, cell_batch.to(torch.float32), latent_mu, latent_logvar)\n",
    "\n",
    "            test_loss_avg[-1] += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "        test_loss_avg[-1] /= num_batches\n",
    "\n",
    "        print('Epoch [%d / %d] average testing reconstruction error: %f' % (epoch+1, num_epochs, test_loss_avg[-1]))\n",
    "        print('Current time: ', datetime.now().strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "\n",
    "path = '/Users/ryanyutian/Desktop/PBMC68k_project/models/50_25_9_VAE/50_25_9_VAE.pt'\n",
    "\n",
    "torch.save(vae.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model performance\n",
    "\n",
    "output_df_dict = {'training_loss_avg': train_loss_avg, 'testing_loss_avg': test_loss_avg}\n",
    "output_df = pd.DataFrame.from_dict(output_df_dict, orient='index')\n",
    "\n",
    "path = '/Users/ryanyutian/Desktop/PBMC68k_project/models/50_25_9_VAE'\n",
    "output_df.to_csv((path + '/'  'performance.csv'), sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training MSE loss over 100 epochs\n",
    "\n",
    "plt.figure(figsize =(14, 10))\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "_ = plt.plot(np.arange(0,100,1), train_loss_avg)\n",
    "\n",
    "_ = plt.ylabel('Average (over the batches) MSE loss in training')\n",
    "_ = plt.xlabel('Epoch')\n",
    "_ = plt.ylim([0, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot testing MSE loss over 100 epochs\n",
    "\n",
    "plt.figure(figsize =(14, 10))\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "_ = plt.plot(np.arange(0,101,50), test_loss_avg)\n",
    "\n",
    "_ = plt.ylabel('Average (over the batches) MSE loss in testing')\n",
    "_ = plt.xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Reconstructing classes from latent space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.eval()\n",
    "\n",
    "# Get latent space vectors \n",
    "# (for each sample, there is a 9 dimensional vector of mu,\n",
    "# and a 9 dimensional vector of logvar describing the distribution)\n",
    "latent_mu, latent_logvar = vae.encoder(torch.from_numpy(normalized_expression_pure_array).to(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a np.array as training dataset\n",
    "latent_vars = []\n",
    "\n",
    "for i in range(len(latent_mu)):\n",
    "    \n",
    "    temp_row = np.concatenate((latent_mu[i].detach().numpy(), latent_logvar[i].detach().numpy()), axis=None)\n",
    "    latent_vars.append(temp_row)\n",
    "    \n",
    "latent_vars = np.array(latent_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92043, 18)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_vars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Neural Network architecture\n",
    "class MLPNNet(nn.Module):\n",
    "   \n",
    "    def __init__(self, layer_size_list, output_size):\n",
    "       \n",
    "        super(MLPNNet, self).__init__()\n",
    "        \n",
    "        # Save some model parameters\n",
    "        self.input_size = layer_size_list[0]\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # Define hidden layers\n",
    "        self.hidden = nn.ModuleList()\n",
    "        for k in range(len(layer_size_list)-1):\n",
    "            self.hidden.append(nn.Linear(layer_size_list[k], layer_size_list[k+1]))\n",
    "       \n",
    "        # Last hidden layer to output layer\n",
    "        self.out = nn.Linear(layer_size_list[-1], output_size)\n",
    "       \n",
    "    # ReLu activation function used for hidden layers\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Feedforward\n",
    "        for layer in self.hidden:\n",
    "            x = F.relu(layer(x))\n",
    "\n",
    "        # Generate output\n",
    "        output= self.out(x)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_from_MLP_output(output):\n",
    "    \n",
    "    # Apply softmax function to get probability for each class (one-hot encoding)\n",
    "    pred = F.softmax(output, dim = 1)\n",
    "    \n",
    "    # Convert prediction back to numpy array\n",
    "    MLP_dec = pred.detach().numpy()\n",
    "    \n",
    "    # Get predicted labels from probabilities\n",
    "    MLP_predicted_labels = np.argmax(MLP_dec, axis=1)\n",
    "\n",
    "    return MLP_predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and testing set from the pure data\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(latent_vars, cell_labels_pure, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8]),\n",
       " array([7388, 6718, 8360, 8220, 9545, 8183, 8161, 8047, 9012]))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8]),\n",
       " array([1844, 1667, 2119, 2043, 2408, 2041, 2048, 2038, 2201]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "Epoch [1 / 500] average training loss: 2.215245\n",
      "Current epoch: 1\n",
      "Current time:  01:10:53\n",
      "Train accuracy = 0.11113072765298639\n",
      "Test accuracy = 0.11086968330707805\n",
      "Epoch [2 / 500] average training loss: 2.215067\n",
      "Epoch [3 / 500] average training loss: 2.214797\n",
      "Epoch [4 / 500] average training loss: 2.213942\n",
      "Epoch [5 / 500] average training loss: 2.214393\n",
      "Epoch [6 / 500] average training loss: 2.214180\n",
      "Epoch [7 / 500] average training loss: 2.213320\n",
      "Epoch [8 / 500] average training loss: 2.213287\n",
      "Epoch [9 / 500] average training loss: 2.212961\n",
      "Epoch [10 / 500] average training loss: 2.212606\n",
      "Epoch [11 / 500] average training loss: 2.211511\n",
      "Epoch [12 / 500] average training loss: 2.211603\n",
      "Epoch [13 / 500] average training loss: 2.212183\n",
      "Epoch [14 / 500] average training loss: 2.211896\n",
      "Epoch [15 / 500] average training loss: 2.210937\n",
      "Epoch [16 / 500] average training loss: 2.209842\n",
      "Epoch [17 / 500] average training loss: 2.210506\n",
      "Epoch [18 / 500] average training loss: 2.209602\n",
      "Epoch [19 / 500] average training loss: 2.209646\n",
      "Epoch [20 / 500] average training loss: 2.209444\n",
      "Epoch [21 / 500] average training loss: 2.209247\n",
      "Epoch [22 / 500] average training loss: 2.209399\n",
      "Epoch [23 / 500] average training loss: 2.208590\n",
      "Epoch [24 / 500] average training loss: 2.208377\n",
      "Epoch [25 / 500] average training loss: 2.207800\n",
      "Epoch [26 / 500] average training loss: 2.207727\n",
      "Epoch [27 / 500] average training loss: 2.207523\n",
      "Epoch [28 / 500] average training loss: 2.207327\n",
      "Epoch [29 / 500] average training loss: 2.206603\n",
      "Epoch [30 / 500] average training loss: 2.206649\n",
      "Epoch [31 / 500] average training loss: 2.206570\n",
      "Epoch [32 / 500] average training loss: 2.206451\n",
      "Epoch [33 / 500] average training loss: 2.206468\n",
      "Epoch [34 / 500] average training loss: 2.206075\n",
      "Epoch [35 / 500] average training loss: 2.205732\n",
      "Epoch [36 / 500] average training loss: 2.205029\n",
      "Epoch [37 / 500] average training loss: 2.205138\n",
      "Epoch [38 / 500] average training loss: 2.204473\n",
      "Epoch [39 / 500] average training loss: 2.204521\n",
      "Epoch [40 / 500] average training loss: 2.204508\n",
      "Epoch [41 / 500] average training loss: 2.204323\n",
      "Epoch [42 / 500] average training loss: 2.203763\n",
      "Epoch [43 / 500] average training loss: 2.203864\n",
      "Epoch [44 / 500] average training loss: 2.203412\n",
      "Epoch [45 / 500] average training loss: 2.202972\n",
      "Epoch [46 / 500] average training loss: 2.202903\n",
      "Epoch [47 / 500] average training loss: 2.203516\n",
      "Epoch [48 / 500] average training loss: 2.202981\n",
      "Epoch [49 / 500] average training loss: 2.202937\n",
      "Epoch [50 / 500] average training loss: 2.202747\n",
      "Current epoch: 50\n",
      "Current time:  01:10:53\n",
      "Train accuracy = 0.11113072765298639\n",
      "Test accuracy = 0.11086968330707805\n",
      "Epoch [51 / 500] average training loss: 2.202737\n",
      "Epoch [52 / 500] average training loss: 2.201742\n",
      "Epoch [53 / 500] average training loss: 2.201542\n",
      "Epoch [54 / 500] average training loss: 2.201113\n",
      "Epoch [55 / 500] average training loss: 2.201240\n",
      "Epoch [56 / 500] average training loss: 2.201259\n",
      "Epoch [57 / 500] average training loss: 2.201034\n",
      "Epoch [58 / 500] average training loss: 2.200909\n",
      "Epoch [59 / 500] average training loss: 2.200947\n",
      "Epoch [60 / 500] average training loss: 2.200643\n",
      "Epoch [61 / 500] average training loss: 2.200412\n",
      "Epoch [62 / 500] average training loss: 2.199684\n",
      "Epoch [63 / 500] average training loss: 2.200191\n",
      "Epoch [64 / 500] average training loss: 2.199855\n",
      "Epoch [65 / 500] average training loss: 2.200274\n",
      "Epoch [66 / 500] average training loss: 2.199893\n",
      "Epoch [67 / 500] average training loss: 2.200433\n",
      "Epoch [68 / 500] average training loss: 2.199340\n",
      "Epoch [69 / 500] average training loss: 2.199202\n",
      "Epoch [70 / 500] average training loss: 2.198445\n",
      "Epoch [71 / 500] average training loss: 2.198765\n",
      "Epoch [72 / 500] average training loss: 2.198884\n",
      "Epoch [73 / 500] average training loss: 2.198787\n",
      "Epoch [74 / 500] average training loss: 2.198636\n",
      "Epoch [75 / 500] average training loss: 2.198470\n",
      "Epoch [76 / 500] average training loss: 2.198852\n",
      "Epoch [77 / 500] average training loss: 2.198660\n",
      "Epoch [78 / 500] average training loss: 2.198215\n",
      "Epoch [79 / 500] average training loss: 2.198215\n",
      "Epoch [80 / 500] average training loss: 2.197860\n",
      "Epoch [81 / 500] average training loss: 2.197800\n",
      "Epoch [82 / 500] average training loss: 2.197068\n",
      "Epoch [83 / 500] average training loss: 2.197544\n",
      "Epoch [84 / 500] average training loss: 2.197535\n",
      "Epoch [85 / 500] average training loss: 2.197218\n",
      "Epoch [86 / 500] average training loss: 2.197044\n",
      "Epoch [87 / 500] average training loss: 2.196663\n",
      "Epoch [88 / 500] average training loss: 2.196879\n",
      "Epoch [89 / 500] average training loss: 2.197193\n",
      "Epoch [90 / 500] average training loss: 2.197134\n",
      "Epoch [91 / 500] average training loss: 2.196462\n",
      "Epoch [92 / 500] average training loss: 2.196892\n",
      "Epoch [93 / 500] average training loss: 2.196521\n",
      "Epoch [94 / 500] average training loss: 2.195857\n",
      "Epoch [95 / 500] average training loss: 2.195912\n",
      "Epoch [96 / 500] average training loss: 2.195907\n",
      "Epoch [97 / 500] average training loss: 2.195256\n",
      "Epoch [98 / 500] average training loss: 2.196070\n",
      "Epoch [99 / 500] average training loss: 2.196193\n",
      "Epoch [100 / 500] average training loss: 2.195890\n",
      "Current epoch: 100\n",
      "Current time:  01:10:54\n",
      "Train accuracy = 0.1296276176766168\n",
      "Test accuracy = 0.1308055842251073\n",
      "Epoch [101 / 500] average training loss: 2.196276\n",
      "Epoch [102 / 500] average training loss: 2.196198\n",
      "Epoch [103 / 500] average training loss: 2.195791\n",
      "Epoch [104 / 500] average training loss: 2.195692\n",
      "Epoch [105 / 500] average training loss: 2.195252\n",
      "Epoch [106 / 500] average training loss: 2.195630\n",
      "Epoch [107 / 500] average training loss: 2.195523\n",
      "Epoch [108 / 500] average training loss: 2.195767\n",
      "Epoch [109 / 500] average training loss: 2.195422\n",
      "Epoch [110 / 500] average training loss: 2.195265\n",
      "Epoch [111 / 500] average training loss: 2.195474\n",
      "Epoch [112 / 500] average training loss: 2.195058\n",
      "Epoch [113 / 500] average training loss: 2.195074\n",
      "Epoch [114 / 500] average training loss: 2.194895\n",
      "Epoch [115 / 500] average training loss: 2.194858\n",
      "Epoch [116 / 500] average training loss: 2.195176\n",
      "Epoch [117 / 500] average training loss: 2.194740\n",
      "Epoch [118 / 500] average training loss: 2.194363\n",
      "Epoch [119 / 500] average training loss: 2.194614\n",
      "Epoch [120 / 500] average training loss: 2.194719\n",
      "Epoch [121 / 500] average training loss: 2.194346\n",
      "Epoch [122 / 500] average training loss: 2.194242\n",
      "Epoch [123 / 500] average training loss: 2.194274\n",
      "Epoch [124 / 500] average training loss: 2.194404\n",
      "Epoch [125 / 500] average training loss: 2.194376\n",
      "Epoch [126 / 500] average training loss: 2.194102\n",
      "Epoch [127 / 500] average training loss: 2.194294\n",
      "Epoch [128 / 500] average training loss: 2.194388\n",
      "Epoch [129 / 500] average training loss: 2.193967\n",
      "Epoch [130 / 500] average training loss: 2.194244\n",
      "Epoch [131 / 500] average training loss: 2.194181\n",
      "Epoch [132 / 500] average training loss: 2.194196\n",
      "Epoch [133 / 500] average training loss: 2.193946\n",
      "Epoch [134 / 500] average training loss: 2.194087\n",
      "Epoch [135 / 500] average training loss: 2.194299\n",
      "Epoch [136 / 500] average training loss: 2.194342\n",
      "Epoch [137 / 500] average training loss: 2.194020\n",
      "Epoch [138 / 500] average training loss: 2.193837\n",
      "Epoch [139 / 500] average training loss: 2.193199\n",
      "Epoch [140 / 500] average training loss: 2.193210\n",
      "Epoch [141 / 500] average training loss: 2.192828\n",
      "Epoch [142 / 500] average training loss: 2.193459\n",
      "Epoch [143 / 500] average training loss: 2.193330\n",
      "Epoch [144 / 500] average training loss: 2.193439\n",
      "Epoch [145 / 500] average training loss: 2.193606\n",
      "Epoch [146 / 500] average training loss: 2.193320\n",
      "Epoch [147 / 500] average training loss: 2.193625\n",
      "Epoch [148 / 500] average training loss: 2.193801\n",
      "Epoch [149 / 500] average training loss: 2.193522\n",
      "Epoch [150 / 500] average training loss: 2.193170\n",
      "Current epoch: 150\n",
      "Current time:  01:10:55\n",
      "Train accuracy = 0.1296276176766168\n",
      "Test accuracy = 0.1308055842251073\n",
      "Epoch [151 / 500] average training loss: 2.193160\n",
      "Epoch [152 / 500] average training loss: 2.193080\n",
      "Epoch [153 / 500] average training loss: 2.193335\n",
      "Epoch [154 / 500] average training loss: 2.193401\n",
      "Epoch [155 / 500] average training loss: 2.193678\n",
      "Epoch [156 / 500] average training loss: 2.193692\n",
      "Epoch [157 / 500] average training loss: 2.193303\n",
      "Epoch [158 / 500] average training loss: 2.193237\n",
      "Epoch [159 / 500] average training loss: 2.193204\n",
      "Epoch [160 / 500] average training loss: 2.192881\n",
      "Epoch [161 / 500] average training loss: 2.192861\n",
      "Epoch [162 / 500] average training loss: 2.192594\n",
      "Epoch [163 / 500] average training loss: 2.192855\n",
      "Epoch [164 / 500] average training loss: 2.192783\n",
      "Epoch [165 / 500] average training loss: 2.192786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [166 / 500] average training loss: 2.193166\n",
      "Epoch [167 / 500] average training loss: 2.193119\n",
      "Epoch [168 / 500] average training loss: 2.193419\n",
      "Epoch [169 / 500] average training loss: 2.193493\n",
      "Epoch [170 / 500] average training loss: 2.193480\n",
      "Epoch [171 / 500] average training loss: 2.193152\n",
      "Epoch [172 / 500] average training loss: 2.193136\n",
      "Epoch [173 / 500] average training loss: 2.193644\n",
      "Epoch [174 / 500] average training loss: 2.193638\n",
      "Epoch [175 / 500] average training loss: 2.193438\n",
      "Epoch [176 / 500] average training loss: 2.193367\n",
      "Epoch [177 / 500] average training loss: 2.193428\n",
      "Epoch [178 / 500] average training loss: 2.193324\n",
      "Epoch [179 / 500] average training loss: 2.193340\n",
      "Epoch [180 / 500] average training loss: 2.193308\n",
      "Epoch [181 / 500] average training loss: 2.193303\n",
      "Epoch [182 / 500] average training loss: 2.193307\n",
      "Epoch [183 / 500] average training loss: 2.193257\n",
      "Epoch [184 / 500] average training loss: 2.193239\n",
      "Epoch [185 / 500] average training loss: 2.193018\n",
      "Epoch [186 / 500] average training loss: 2.193048\n",
      "Epoch [187 / 500] average training loss: 2.192982\n",
      "Epoch [188 / 500] average training loss: 2.192631\n",
      "Epoch [189 / 500] average training loss: 2.192870\n",
      "Epoch [190 / 500] average training loss: 2.193135\n",
      "Epoch [191 / 500] average training loss: 2.193140\n",
      "Epoch [192 / 500] average training loss: 2.193216\n",
      "Epoch [193 / 500] average training loss: 2.193282\n",
      "Epoch [194 / 500] average training loss: 2.193210\n",
      "Epoch [195 / 500] average training loss: 2.193177\n",
      "Epoch [196 / 500] average training loss: 2.193148\n",
      "Epoch [197 / 500] average training loss: 2.193154\n",
      "Epoch [198 / 500] average training loss: 2.193513\n",
      "Epoch [199 / 500] average training loss: 2.192677\n",
      "Epoch [200 / 500] average training loss: 2.192739\n",
      "Current epoch: 200\n",
      "Current time:  01:10:56\n",
      "Train accuracy = 0.1296276176766168\n",
      "Test accuracy = 0.1308055842251073\n",
      "Epoch [201 / 500] average training loss: 2.192420\n",
      "Epoch [202 / 500] average training loss: 2.192416\n",
      "Epoch [203 / 500] average training loss: 2.192419\n",
      "Epoch [204 / 500] average training loss: 2.192399\n",
      "Epoch [205 / 500] average training loss: 2.192045\n",
      "Epoch [206 / 500] average training loss: 2.192164\n",
      "Epoch [207 / 500] average training loss: 2.192068\n",
      "Epoch [208 / 500] average training loss: 2.192364\n",
      "Epoch [209 / 500] average training loss: 2.192346\n",
      "Epoch [210 / 500] average training loss: 2.192369\n",
      "Epoch [211 / 500] average training loss: 2.192383\n",
      "Epoch [212 / 500] average training loss: 2.192364\n",
      "Epoch [213 / 500] average training loss: 2.192563\n",
      "Epoch [214 / 500] average training loss: 2.192628\n",
      "Epoch [215 / 500] average training loss: 2.192662\n",
      "Epoch [216 / 500] average training loss: 2.192317\n",
      "Epoch [217 / 500] average training loss: 2.192313\n",
      "Epoch [218 / 500] average training loss: 2.192381\n",
      "Epoch [219 / 500] average training loss: 2.192297\n",
      "Epoch [220 / 500] average training loss: 2.192263\n",
      "Epoch [221 / 500] average training loss: 2.192630\n",
      "Epoch [222 / 500] average training loss: 2.192316\n",
      "Epoch [223 / 500] average training loss: 2.192291\n",
      "Epoch [224 / 500] average training loss: 2.192576\n",
      "Epoch [225 / 500] average training loss: 2.192492\n",
      "Epoch [226 / 500] average training loss: 2.192813\n",
      "Epoch [227 / 500] average training loss: 2.192811\n",
      "Epoch [228 / 500] average training loss: 2.192544\n",
      "Epoch [229 / 500] average training loss: 2.192535\n",
      "Epoch [230 / 500] average training loss: 2.192591\n",
      "Epoch [231 / 500] average training loss: 2.192586\n",
      "Epoch [232 / 500] average training loss: 2.192524\n",
      "Epoch [233 / 500] average training loss: 2.192622\n",
      "Epoch [234 / 500] average training loss: 2.192621\n",
      "Epoch [235 / 500] average training loss: 2.192616\n",
      "Epoch [236 / 500] average training loss: 2.192621\n",
      "Epoch [237 / 500] average training loss: 2.192618\n",
      "Epoch [238 / 500] average training loss: 2.192886\n",
      "Epoch [239 / 500] average training loss: 2.192554\n",
      "Epoch [240 / 500] average training loss: 2.192493\n",
      "Epoch [241 / 500] average training loss: 2.192487\n",
      "Epoch [242 / 500] average training loss: 2.192510\n",
      "Epoch [243 / 500] average training loss: 2.192510\n",
      "Epoch [244 / 500] average training loss: 2.192506\n",
      "Epoch [245 / 500] average training loss: 2.192243\n",
      "Epoch [246 / 500] average training loss: 2.192240\n",
      "Epoch [247 / 500] average training loss: 2.192241\n",
      "Epoch [248 / 500] average training loss: 2.192296\n",
      "Epoch [249 / 500] average training loss: 2.192291\n",
      "Epoch [250 / 500] average training loss: 2.192204\n",
      "Current epoch: 250\n",
      "Current time:  01:10:57\n",
      "Train accuracy = 0.1296276176766168\n",
      "Test accuracy = 0.1308055842251073\n",
      "Epoch [251 / 500] average training loss: 2.192229\n",
      "Epoch [252 / 500] average training loss: 2.192219\n",
      "Epoch [253 / 500] average training loss: 2.192204\n",
      "Epoch [254 / 500] average training loss: 2.192226\n",
      "Epoch [255 / 500] average training loss: 2.192221\n",
      "Epoch [256 / 500] average training loss: 2.191897\n",
      "Epoch [257 / 500] average training loss: 2.192251\n",
      "Epoch [258 / 500] average training loss: 2.192252\n",
      "Epoch [259 / 500] average training loss: 2.192238\n",
      "Epoch [260 / 500] average training loss: 2.192241\n",
      "Epoch [261 / 500] average training loss: 2.192236\n",
      "Epoch [262 / 500] average training loss: 2.192236\n",
      "Epoch [263 / 500] average training loss: 2.192154\n",
      "Epoch [264 / 500] average training loss: 2.192176\n",
      "Epoch [265 / 500] average training loss: 2.192170\n",
      "Epoch [266 / 500] average training loss: 2.192175\n",
      "Epoch [267 / 500] average training loss: 2.192239\n",
      "Epoch [268 / 500] average training loss: 2.192244\n",
      "Epoch [269 / 500] average training loss: 2.192239\n",
      "Epoch [270 / 500] average training loss: 2.192239\n",
      "Epoch [271 / 500] average training loss: 2.191884\n",
      "Epoch [272 / 500] average training loss: 2.191970\n",
      "Epoch [273 / 500] average training loss: 2.191965\n",
      "Epoch [274 / 500] average training loss: 2.191967\n",
      "Epoch [275 / 500] average training loss: 2.191966\n",
      "Epoch [276 / 500] average training loss: 2.191945\n",
      "Epoch [277 / 500] average training loss: 2.191955\n",
      "Epoch [278 / 500] average training loss: 2.191955\n",
      "Epoch [279 / 500] average training loss: 2.191949\n",
      "Epoch [280 / 500] average training loss: 2.191951\n",
      "Epoch [281 / 500] average training loss: 2.191864\n",
      "Epoch [282 / 500] average training loss: 2.191863\n",
      "Epoch [283 / 500] average training loss: 2.191884\n",
      "Epoch [284 / 500] average training loss: 2.191957\n",
      "Epoch [285 / 500] average training loss: 2.191951\n",
      "Epoch [286 / 500] average training loss: 2.191952\n",
      "Epoch [287 / 500] average training loss: 2.191951\n",
      "Epoch [288 / 500] average training loss: 2.191930\n",
      "Epoch [289 / 500] average training loss: 2.191937\n",
      "Epoch [290 / 500] average training loss: 2.191936\n",
      "Epoch [291 / 500] average training loss: 2.191941\n",
      "Epoch [292 / 500] average training loss: 2.191936\n",
      "Epoch [293 / 500] average training loss: 2.191937\n",
      "Epoch [294 / 500] average training loss: 2.191941\n",
      "Epoch [295 / 500] average training loss: 2.191940\n",
      "Epoch [296 / 500] average training loss: 2.191940\n",
      "Epoch [297 / 500] average training loss: 2.192256\n",
      "Epoch [298 / 500] average training loss: 2.192255\n",
      "Epoch [299 / 500] average training loss: 2.192255\n",
      "Epoch [300 / 500] average training loss: 2.192256\n",
      "Current epoch: 300\n",
      "Current time:  01:10:57\n",
      "Train accuracy = 0.1296276176766168\n",
      "Test accuracy = 0.1308055842251073\n",
      "Epoch [301 / 500] average training loss: 2.192251\n",
      "Epoch [302 / 500] average training loss: 2.192252\n",
      "Epoch [303 / 500] average training loss: 2.192250\n",
      "Epoch [304 / 500] average training loss: 2.192251\n",
      "Epoch [305 / 500] average training loss: 2.192250\n",
      "Epoch [306 / 500] average training loss: 2.192229\n",
      "Epoch [307 / 500] average training loss: 2.192235\n",
      "Epoch [308 / 500] average training loss: 2.192252\n",
      "Epoch [309 / 500] average training loss: 2.192251\n",
      "Epoch [310 / 500] average training loss: 2.192252\n",
      "Epoch [311 / 500] average training loss: 2.192251\n",
      "Epoch [312 / 500] average training loss: 2.192251\n",
      "Epoch [313 / 500] average training loss: 2.192246\n",
      "Epoch [314 / 500] average training loss: 2.192248\n",
      "Epoch [315 / 500] average training loss: 2.192244\n",
      "Epoch [316 / 500] average training loss: 2.192244\n",
      "Epoch [317 / 500] average training loss: 2.192243\n",
      "Epoch [318 / 500] average training loss: 2.192243\n",
      "Epoch [319 / 500] average training loss: 2.192244\n",
      "Epoch [320 / 500] average training loss: 2.192244\n",
      "Epoch [321 / 500] average training loss: 2.192156\n",
      "Epoch [322 / 500] average training loss: 2.192581\n",
      "Epoch [323 / 500] average training loss: 2.192580\n",
      "Epoch [324 / 500] average training loss: 2.192581\n",
      "Epoch [325 / 500] average training loss: 2.192580\n",
      "Epoch [326 / 500] average training loss: 2.192579\n",
      "Epoch [327 / 500] average training loss: 2.192580\n",
      "Epoch [328 / 500] average training loss: 2.192580\n",
      "Epoch [329 / 500] average training loss: 2.192579\n",
      "Epoch [330 / 500] average training loss: 2.192580\n",
      "Epoch [331 / 500] average training loss: 2.192579\n",
      "Epoch [332 / 500] average training loss: 2.192574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [333 / 500] average training loss: 2.192575\n",
      "Epoch [334 / 500] average training loss: 2.192575\n",
      "Epoch [335 / 500] average training loss: 2.192575\n",
      "Epoch [336 / 500] average training loss: 2.192575\n",
      "Epoch [337 / 500] average training loss: 2.192575\n",
      "Epoch [338 / 500] average training loss: 2.192575\n",
      "Epoch [339 / 500] average training loss: 2.192579\n",
      "Epoch [340 / 500] average training loss: 2.192579\n",
      "Epoch [341 / 500] average training loss: 2.192579\n",
      "Epoch [342 / 500] average training loss: 2.192579\n",
      "Epoch [343 / 500] average training loss: 2.192579\n",
      "Epoch [344 / 500] average training loss: 2.192579\n",
      "Epoch [345 / 500] average training loss: 2.192579\n",
      "Epoch [346 / 500] average training loss: 2.192579\n",
      "Epoch [347 / 500] average training loss: 2.192579\n",
      "Epoch [348 / 500] average training loss: 2.192579\n",
      "Epoch [349 / 500] average training loss: 2.192579\n",
      "Epoch [350 / 500] average training loss: 2.192585\n",
      "Current epoch: 350\n",
      "Current time:  01:10:58\n",
      "Train accuracy = 0.1296276176766168\n",
      "Test accuracy = 0.1308055842251073\n",
      "Epoch [351 / 500] average training loss: 2.192564\n",
      "Epoch [352 / 500] average training loss: 2.192563\n",
      "Epoch [353 / 500] average training loss: 2.192563\n",
      "Epoch [354 / 500] average training loss: 2.192563\n",
      "Epoch [355 / 500] average training loss: 2.192563\n",
      "Epoch [356 / 500] average training loss: 2.192563\n",
      "Epoch [357 / 500] average training loss: 2.192563\n",
      "Epoch [358 / 500] average training loss: 2.192563\n",
      "Epoch [359 / 500] average training loss: 2.192563\n",
      "Epoch [360 / 500] average training loss: 2.192563\n",
      "Epoch [361 / 500] average training loss: 2.192563\n",
      "Epoch [362 / 500] average training loss: 2.192563\n",
      "Epoch [363 / 500] average training loss: 2.192563\n",
      "Epoch [364 / 500] average training loss: 2.192563\n",
      "Epoch [365 / 500] average training loss: 2.192563\n",
      "Epoch [366 / 500] average training loss: 2.192563\n",
      "Epoch [367 / 500] average training loss: 2.192563\n",
      "Epoch [368 / 500] average training loss: 2.192563\n",
      "Epoch [369 / 500] average training loss: 2.192563\n",
      "Epoch [370 / 500] average training loss: 2.192562\n",
      "Epoch [371 / 500] average training loss: 2.192562\n",
      "Epoch [372 / 500] average training loss: 2.192562\n",
      "Epoch [373 / 500] average training loss: 2.192562\n",
      "Epoch [374 / 500] average training loss: 2.192562\n",
      "Epoch [375 / 500] average training loss: 2.192562\n",
      "Epoch [376 / 500] average training loss: 2.192562\n",
      "Epoch [377 / 500] average training loss: 2.192562\n",
      "Epoch [378 / 500] average training loss: 2.192562\n",
      "Epoch [379 / 500] average training loss: 2.192562\n",
      "Epoch [380 / 500] average training loss: 2.192562\n",
      "Epoch [381 / 500] average training loss: 2.192562\n",
      "Epoch [382 / 500] average training loss: 2.192562\n",
      "Epoch [383 / 500] average training loss: 2.192562\n",
      "Epoch [384 / 500] average training loss: 2.192562\n",
      "Epoch [385 / 500] average training loss: 2.192562\n",
      "Epoch [386 / 500] average training loss: 2.192562\n",
      "Epoch [387 / 500] average training loss: 2.192562\n",
      "Epoch [388 / 500] average training loss: 2.192565\n",
      "Epoch [389 / 500] average training loss: 2.192573\n",
      "Epoch [390 / 500] average training loss: 2.192581\n",
      "Epoch [391 / 500] average training loss: 2.192584\n",
      "Epoch [392 / 500] average training loss: 2.192585\n",
      "Epoch [393 / 500] average training loss: 2.192586\n",
      "Epoch [394 / 500] average training loss: 2.192586\n",
      "Epoch [395 / 500] average training loss: 2.192586\n",
      "Epoch [396 / 500] average training loss: 2.192586\n",
      "Epoch [397 / 500] average training loss: 2.192586\n",
      "Epoch [398 / 500] average training loss: 2.192586\n",
      "Epoch [399 / 500] average training loss: 2.192586\n",
      "Epoch [400 / 500] average training loss: 2.192586\n",
      "Current epoch: 400\n",
      "Current time:  01:10:59\n",
      "Train accuracy = 0.1296276176766168\n",
      "Test accuracy = 0.1308055842251073\n",
      "Epoch [401 / 500] average training loss: 2.192586\n",
      "Epoch [402 / 500] average training loss: 2.192586\n",
      "Epoch [403 / 500] average training loss: 2.192586\n",
      "Epoch [404 / 500] average training loss: 2.192586\n",
      "Epoch [405 / 500] average training loss: 2.192586\n",
      "Epoch [406 / 500] average training loss: 2.192586\n",
      "Epoch [407 / 500] average training loss: 2.192586\n",
      "Epoch [408 / 500] average training loss: 2.192586\n",
      "Epoch [409 / 500] average training loss: 2.192586\n",
      "Epoch [410 / 500] average training loss: 2.192586\n",
      "Epoch [411 / 500] average training loss: 2.192586\n",
      "Epoch [412 / 500] average training loss: 2.192587\n",
      "Epoch [413 / 500] average training loss: 2.192587\n",
      "Epoch [414 / 500] average training loss: 2.192587\n",
      "Epoch [415 / 500] average training loss: 2.192587\n",
      "Epoch [416 / 500] average training loss: 2.192587\n",
      "Epoch [417 / 500] average training loss: 2.192587\n",
      "Epoch [418 / 500] average training loss: 2.192587\n",
      "Epoch [419 / 500] average training loss: 2.192587\n",
      "Epoch [420 / 500] average training loss: 2.192587\n",
      "Epoch [421 / 500] average training loss: 2.192587\n",
      "Epoch [422 / 500] average training loss: 2.192587\n",
      "Epoch [423 / 500] average training loss: 2.192587\n",
      "Epoch [424 / 500] average training loss: 2.192587\n",
      "Epoch [425 / 500] average training loss: 2.192587\n",
      "Epoch [426 / 500] average training loss: 2.192587\n",
      "Epoch [427 / 500] average training loss: 2.192587\n",
      "Epoch [428 / 500] average training loss: 2.192587\n",
      "Epoch [429 / 500] average training loss: 2.192587\n",
      "Epoch [430 / 500] average training loss: 2.192587\n",
      "Epoch [431 / 500] average training loss: 2.192587\n",
      "Epoch [432 / 500] average training loss: 2.192587\n",
      "Epoch [433 / 500] average training loss: 2.192587\n",
      "Epoch [434 / 500] average training loss: 2.192587\n",
      "Epoch [435 / 500] average training loss: 2.192587\n",
      "Epoch [436 / 500] average training loss: 2.192587\n",
      "Epoch [437 / 500] average training loss: 2.192587\n",
      "Epoch [438 / 500] average training loss: 2.192587\n",
      "Epoch [439 / 500] average training loss: 2.192587\n",
      "Epoch [440 / 500] average training loss: 2.192587\n",
      "Epoch [441 / 500] average training loss: 2.192587\n",
      "Epoch [442 / 500] average training loss: 2.192587\n",
      "Epoch [443 / 500] average training loss: 2.192587\n",
      "Epoch [444 / 500] average training loss: 2.192587\n",
      "Epoch [445 / 500] average training loss: 2.192587\n",
      "Epoch [446 / 500] average training loss: 2.192587\n",
      "Epoch [447 / 500] average training loss: 2.192587\n",
      "Epoch [448 / 500] average training loss: 2.192587\n",
      "Epoch [449 / 500] average training loss: 2.192587\n",
      "Epoch [450 / 500] average training loss: 2.192587\n",
      "Current epoch: 450\n",
      "Current time:  01:11:00\n",
      "Train accuracy = 0.1296276176766168\n",
      "Test accuracy = 0.1308055842251073\n",
      "Epoch [451 / 500] average training loss: 2.192587\n",
      "Epoch [452 / 500] average training loss: 2.192587\n",
      "Epoch [453 / 500] average training loss: 2.192587\n",
      "Epoch [454 / 500] average training loss: 2.192587\n",
      "Epoch [455 / 500] average training loss: 2.192587\n",
      "Epoch [456 / 500] average training loss: 2.192587\n",
      "Epoch [457 / 500] average training loss: 2.192587\n",
      "Epoch [458 / 500] average training loss: 2.192587\n",
      "Epoch [459 / 500] average training loss: 2.192587\n",
      "Epoch [460 / 500] average training loss: 2.192587\n",
      "Epoch [461 / 500] average training loss: 2.192587\n",
      "Epoch [462 / 500] average training loss: 2.192587\n",
      "Epoch [463 / 500] average training loss: 2.192587\n",
      "Epoch [464 / 500] average training loss: 2.192587\n",
      "Epoch [465 / 500] average training loss: 2.192587\n",
      "Epoch [466 / 500] average training loss: 2.192587\n",
      "Epoch [467 / 500] average training loss: 2.192587\n",
      "Epoch [468 / 500] average training loss: 2.192587\n",
      "Epoch [469 / 500] average training loss: 2.192587\n",
      "Epoch [470 / 500] average training loss: 2.192587\n",
      "Epoch [471 / 500] average training loss: 2.192587\n",
      "Epoch [472 / 500] average training loss: 2.192587\n",
      "Epoch [473 / 500] average training loss: 2.192587\n",
      "Epoch [474 / 500] average training loss: 2.192587\n",
      "Epoch [475 / 500] average training loss: 2.192587\n",
      "Epoch [476 / 500] average training loss: 2.192587\n",
      "Epoch [477 / 500] average training loss: 2.192587\n",
      "Epoch [478 / 500] average training loss: 2.192587\n",
      "Epoch [479 / 500] average training loss: 2.192587\n",
      "Epoch [480 / 500] average training loss: 2.192587\n",
      "Epoch [481 / 500] average training loss: 2.192587\n",
      "Epoch [482 / 500] average training loss: 2.192587\n",
      "Epoch [483 / 500] average training loss: 2.192587\n",
      "Epoch [484 / 500] average training loss: 2.192587\n",
      "Epoch [485 / 500] average training loss: 2.192587\n",
      "Epoch [486 / 500] average training loss: 2.192587\n",
      "Epoch [487 / 500] average training loss: 2.192587\n",
      "Epoch [488 / 500] average training loss: 2.192587\n",
      "Epoch [489 / 500] average training loss: 2.192587\n",
      "Epoch [490 / 500] average training loss: 2.192587\n",
      "Epoch [491 / 500] average training loss: 2.192587\n",
      "Epoch [492 / 500] average training loss: 2.192587\n",
      "Epoch [493 / 500] average training loss: 2.192587\n",
      "Epoch [494 / 500] average training loss: 2.192587\n",
      "Epoch [495 / 500] average training loss: 2.192587\n",
      "Epoch [496 / 500] average training loss: 2.192587\n",
      "Epoch [497 / 500] average training loss: 2.192587\n",
      "Epoch [498 / 500] average training loss: 2.192587\n",
      "Epoch [499 / 500] average training loss: 2.192587\n",
      "Epoch [500 / 500] average training loss: 2.192587\n",
      "Current epoch: 500\n",
      "Current time:  01:11:01\n",
      "Train accuracy = 0.1296276176766168\n",
      "Test accuracy = 0.1308055842251073\n"
     ]
    }
   ],
   "source": [
    "# Initialize a very simple MLP to map latent space to class labels\n",
    "model = MLPNNet([18, 10], 9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "# Number of times that the MLP will be trained on the train set\n",
    "n_epochs = 500\n",
    "\n",
    "# Lists to record model training and testing performance\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "print('Training ...')\n",
    "\n",
    "# Loop through the training set to update parameters\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    # Train the model\n",
    "    model.train()\n",
    "\n",
    "    # Get an output by feeding data into the model\n",
    "    out = model(torch.from_numpy(X_train).float())\n",
    "\n",
    "    # Compute loss from output\n",
    "    loss = criterion(out, torch.from_numpy(np.asarray(y_train)).long())\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # Update training performance\n",
    "    train_loss.append(float(loss))\n",
    "    train_accuracy.append(np.mean(get_label_from_MLP_output(out) == y_train))\n",
    "    \n",
    "    print('Epoch [%d / %d] average training loss: %f' % (epoch+1, n_epochs, train_loss[-1]))\n",
    "\n",
    "    # Update other performance lists every 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "                              \n",
    "        # Evaluate the trained MLP model with test data\n",
    "        model.eval()\n",
    "\n",
    "        # Get raw predicted result\n",
    "        test_pred = model(torch.from_numpy(X_test).float())\n",
    "        \n",
    "        # Append test loss\n",
    "        test_loss.append(float(criterion(test_pred, torch.from_numpy(np.asarray(y_test)).long())))\n",
    "\n",
    "        # Get predicted labels \n",
    "        MLP_predicted_labels = get_label_from_MLP_output(test_pred)\n",
    "        temp_test_accuracy = np.mean(MLP_predicted_labels == y_test)\n",
    "        test_accuracy.append(temp_test_accuracy)\n",
    "        \n",
    "    # Print statement every 50 epochs to verify status and time taken\n",
    "    if epoch == 0 or (epoch + 1) % 50 == 0:\n",
    "        \n",
    "        print('Current epoch: ' + str(epoch + 1))\n",
    "        print('Current time: ', datetime.now().strftime(\"%H:%M:%S\"))\n",
    "        print('Train accuracy = ' + str(train_accuracy[-1]))\n",
    "        print('Test accuracy = ' + str(temp_test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task failed, model could not use the latent space to predict original labels\n",
    "## The classification project will thus only focus on the successful MLP models thereafter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
